name: QuASIM-Own Nightly Benchmarks

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggers

permissions:
  contents: write  # Needed to commit benchmark docs

jobs:
  full-benchmark:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]
          pip install scikit-learn xgboost lightgbm
      
      - name: Run full benchmark suite
        run: |
          python -c "
          from quasim.ownai.eval.benchmark import run_benchmark_suite
          from quasim.ownai.eval.reporting import (
              save_results_csv,
              save_results_json,
              generate_markdown_report
          )
          from quasim.ownai.integration.terc_observables import (
              collect_terc_observables,
              save_terc_observables
          )
          from pathlib import Path
          from datetime import datetime
          
          print('Running standard benchmark suite...')
          results = run_benchmark_suite(suite='std', n_repeats=5)
          print(f'Completed {len(results)} benchmark runs')
          
          # Create reports directory
          report_dir = Path('reports')
          report_dir.mkdir(exist_ok=True)
          
          # Save results
          timestamp = datetime.now().strftime('%Y%m%d')
          save_results_csv(results, report_dir / f'benchmark_{timestamp}.csv')
          save_results_json(results, report_dir / f'benchmark_{timestamp}.json')
          
          # Generate markdown report for docs
          generate_markdown_report(
              results,
              Path('docs/ownai/benchmarks.md'),
              title='QuASIM-Own Benchmark Results'
          )
          
          # Save TERC observables
          observables = collect_terc_observables(results)
          save_terc_observables(observables, report_dir / f'terc_{timestamp}.json')
          
          print('Benchmark complete!')
          print(f'Stability margin: {observables[\"stability_margin\"]:.3f}')
          print(f'QGH consensus: {observables[\"qgh_consensus_status\"]}')
          "
      
      - name: Commit benchmark docs
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add docs/ownai/benchmarks.md
          git commit -m "Update benchmark results [skip ci]" || echo "No changes to commit"
          git push || echo "No changes to push"
      
      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: nightly-benchmark-results
          path: reports/
          retention-days: 30
