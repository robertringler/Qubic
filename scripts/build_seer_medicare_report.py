#!/usr/bin/env python3
"""
SEER-Medicare Report Generator

Generates publication-quality reports from pipeline run artifacts.

RESEARCH USE ONLY - Not for clinical diagnosis or treatment decisions.

Usage:
    python scripts/build_seer_medicare_report.py \
        --run_dir artifacts/seer_medicare_run_YYYYMMDD_HHMMSS/

Outputs:
    - REPORT.md: Markdown report
    - REPORT.pdf: PDF report (if reportlab available)
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

# Add repository root to path if needed
repo_root = Path(__file__).parent.parent
if str(repo_root) not in sys.path:
    sys.path.insert(0, str(repo_root))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


REPORT_TEMPLATE = """
# SEER-Medicare Analysis Report

**Generated:** {timestamp}

**Run Directory:** `{run_dir}`

---

## ⚠️ Research Use Disclaimer

> **IMPORTANT: This report is for RESEARCH PURPOSES ONLY.**
>
> - All outputs are research hypotheses requiring validation
> - Results are not approved for clinical diagnosis or treatment
> - Patient identifiers are hashed; no PHI is disclosed
> - Cell sizes < 11 are suppressed per privacy requirements

---

## 1. Executive Summary

{executive_summary}

---

## 2. Data Sources & Governance

### 2.1 Input Data Files

{data_sources_section}

### 2.2 DUA Compliance

{dua_checklist_section}

---

## 3. Cohort Definition

### 3.1 Inclusion/Exclusion Criteria

{cohort_criteria_section}

### 3.2 CONSORT-Style Flow

{cohort_flow_section}

### 3.3 Cohort Characteristics

{cohort_characteristics_section}

---

## 4. Treatment Timeline Summary

### 4.1 Time to First Treatment

{time_to_treatment_section}

### 4.2 Common Treatment Sequences (Top 10)

{treatment_sequences_section}

### 4.3 Lines of Therapy Distribution

{lines_of_therapy_section}

---

## 5. QRATUM Analysis Results

### 5.1 Causal Graph Summary

{causal_graph_section}

### 5.2 Top 10 Hypothesis Sequences

{hypothesis_sequences_section}

### 5.3 Sensitivity Analysis

{sensitivity_section}

---

## 6. Bias & Limitations

{limitations_section}

---

## 7. Reproducibility Appendix

### 7.1 Run Configuration

```json
{run_config_json}
```

### 7.2 Environment Information

```
{environment_info}
```

### 7.3 Git Commit

```
{git_commit}
```

### 7.4 Data Manifest

{manifest_section}

---

*Report generated by QRATUM SEER-Medicare Pipeline*

*{timestamp}*
"""


def load_json_file(filepath: Path) -> dict[str, Any]:
    """Load a JSON file safely."""
    if not filepath.exists():
        return {}
    try:
        with open(filepath, "r") as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"Failed to load {filepath}: {e}")
        return {}


def load_text_file(filepath: Path) -> str:
    """Load a text file safely."""
    if not filepath.exists():
        return "Not available"
    try:
        with open(filepath, "r") as f:
            return f.read().strip()
    except Exception as e:
        logger.warning(f"Failed to load {filepath}: {e}")
        return "Not available"


def format_distribution(dist: dict[str, Any], title: str = "") -> str:
    """Format a distribution as a Markdown table."""
    if not dist:
        return "*No data available*"

    lines = []
    if title:
        lines.append(f"**{title}**\n")
    lines.append("| Category | Count |")
    lines.append("|----------|-------|")

    for key, value in sorted(dist.items(), key=lambda x: str(x[0])):
        lines.append(f"| {key} | {value} |")

    return "\n".join(lines)


def generate_executive_summary(
    cohort_counts: dict[str, Any],
    timeline_summary: dict[str, Any],
    qratum_results: dict[str, Any],
) -> str:
    """Generate executive summary section."""
    lines = []

    # Cohort overview
    included = cohort_counts.get("included", "N/A")
    lines.append(f"- **Cohort Size:** {included} patients")

    # Treatment overview
    n_treated = timeline_summary.get("n_with_any_treatment", "N/A")
    lines.append(f"- **Patients with Treatment:** {n_treated}")

    # QRATUM results
    qratum_status = qratum_results.get("status", "N/A")
    if qratum_status == "complete":
        n_sequences = len(qratum_results.get("sequences", []))
        lines.append(f"- **QRATUM Sequences Generated:** {n_sequences}")
    else:
        lines.append(f"- **QRATUM Status:** {qratum_status}")

    lines.append("")
    lines.append(
        "This analysis explores treatment patterns and generates hypothesis sequences "
        "for research consideration. All findings require validation through prospective studies."
    )

    return "\n".join(lines)


def generate_data_sources_section(manifest: dict[str, Any]) -> str:
    """Generate data sources section."""
    if not manifest:
        return "*No manifest data available*"

    lines = []
    lines.append(f"**Total Files:** {manifest.get('file_count', 'N/A')}")
    lines.append(f"**Total Size:** {manifest.get('total_size_bytes', 0):,} bytes")
    lines.append(f"**Source Directory:** `{manifest.get('source_directory', 'N/A')}`")
    lines.append("")
    lines.append("| File Name | Size (bytes) | SHA256 (first 16 chars) |")
    lines.append("|-----------|--------------|-------------------------|")

    for file_info in manifest.get("files", [])[:20]:  # Limit to 20 files
        name = file_info.get("name", "")
        size = file_info.get("size_bytes", 0)
        sha = file_info.get("sha256", "")[:16]
        lines.append(f"| {name} | {size:,} | {sha}... |")

    if len(manifest.get("files", [])) > 20:
        lines.append(f"| ... | ... | ... |")
        lines.append(f"*({len(manifest['files']) - 20} more files not shown)*")

    return "\n".join(lines)


def generate_dua_checklist_section(checklist: dict[str, Any]) -> str:
    """Generate DUA compliance checklist section."""
    if not checklist:
        return "*No DUA checklist available*"

    lines = []
    lines.append("| Requirement | Status | Notes |")
    lines.append("|-------------|--------|-------|")

    for item in checklist.get("checklist", []):
        req = item.get("item", "")
        status = item.get("status", "")
        notes = item.get("notes", "")
        status_emoji = "✅" if status == "AUTOMATED_CHECK" else "⚠️"
        lines.append(f"| {req} | {status_emoji} {status} | {notes} |")

    issues = checklist.get("issues_found", [])
    if issues:
        lines.append("")
        lines.append("**Issues Found:**")
        for issue in issues:
            lines.append(f"- ⚠️ {issue}")

    return "\n".join(lines)


def generate_cohort_criteria_section(run_config: dict[str, Any]) -> str:
    """Generate cohort criteria section."""
    lines = []
    lines.append("| Parameter | Value |")
    lines.append("|-----------|-------|")

    criteria_fields = [
        ("cancer_site", "Cancer Site"),
        ("histology", "Histology"),
        ("stage", "Stage"),
        ("diagnosis_year_min", "Diagnosis Year Min"),
        ("diagnosis_year_max", "Diagnosis Year Max"),
        ("age_min", "Age Min"),
        ("age_max", "Age Max"),
        ("lookback_days", "Lookback Window (days)"),
        ("followup_days", "Follow-up Window (days)"),
    ]

    for field, label in criteria_fields:
        value = run_config.get(field, "Not specified")
        lines.append(f"| {label} | {value} |")

    return "\n".join(lines)


def generate_cohort_flow_section(cohort_counts: dict[str, Any]) -> str:
    """Generate CONSORT-style cohort flow."""
    lines = []

    total = cohort_counts.get("total_considered", "N/A")
    included = cohort_counts.get("included", "N/A")
    exclusions = cohort_counts.get("exclusion_reasons", {})

    lines.append("```")
    lines.append(f"Total Cases Considered: {total}")
    lines.append("           |")
    lines.append("           v")

    for reason, count in exclusions.items():
        lines.append(f"    [-] Excluded ({reason}): {count}")

    lines.append("           |")
    lines.append("           v")
    lines.append(f"Final Cohort: {included}")
    lines.append("```")

    return "\n".join(lines)


def generate_cohort_characteristics_section(cohort_counts: dict[str, Any]) -> str:
    """Generate cohort characteristics section."""
    sections = []

    # Age distribution
    age_dist = cohort_counts.get("age_distribution", {})
    if age_dist:
        sections.append(format_distribution(age_dist, "Age Distribution"))

    # Sex distribution
    sex_dist = cohort_counts.get("sex_distribution", {})
    if sex_dist:
        sections.append(format_distribution(sex_dist, "Sex Distribution"))

    # Stage distribution
    stage_dist = cohort_counts.get("stage_distribution", {})
    if stage_dist:
        sections.append(format_distribution(stage_dist, "Stage Distribution"))

    # Vital status
    vs_dist = cohort_counts.get("vital_status_distribution", {})
    if vs_dist:
        sections.append(format_distribution(vs_dist, "Vital Status"))

    return "\n\n".join(sections) if sections else "*No characteristic data available*"


def generate_time_to_treatment_section(timeline_summary: dict[str, Any]) -> str:
    """Generate time to first treatment section."""
    lines = []

    median = timeline_summary.get("time_to_first_treatment_median")
    mean = timeline_summary.get("time_to_first_treatment_mean")

    if median is not None:
        lines.append(f"- **Median Time to First Treatment:** {median:.1f} days")
    if mean is not None:
        lines.append(f"- **Mean Time to First Treatment:** {mean:.1f} days")

    if not lines:
        return "*Time to treatment data not available*"

    return "\n".join(lines)


def generate_treatment_sequences_section(timeline_summary: dict[str, Any]) -> str:
    """Generate common treatment sequences section."""
    sequences = timeline_summary.get("common_sequences", [])

    if not sequences:
        return "*No sequence data available*"

    lines = []
    lines.append("| Rank | Sequence | Count |")
    lines.append("|------|----------|-------|")

    for i, seq_info in enumerate(sequences[:10], 1):
        sequence = seq_info.get("sequence", "")
        count = seq_info.get("count", "N/A")
        lines.append(f"| {i} | {sequence} | {count} |")

    return "\n".join(lines)


def generate_lines_of_therapy_section(timeline_summary: dict[str, Any]) -> str:
    """Generate lines of therapy distribution section."""
    dist = timeline_summary.get("lines_of_therapy_distribution", {})
    return format_distribution(dist, "Number of Lines of Therapy")


def generate_causal_graph_section(qratum_results: dict[str, Any]) -> str:
    """Generate causal graph summary section."""
    if qratum_results.get("status") != "complete":
        return "*QRATUM analysis not performed*"

    lines = []
    lines.append(f"- **Graph Hash:** `{qratum_results.get('graph_hash', 'N/A')[:16]}...`")
    lines.append(f"- **Seed:** {qratum_results.get('seed', 'N/A')}")
    lines.append(f"- **Max Depth:** {qratum_results.get('max_depth', 'N/A')}")

    avg_state = qratum_results.get("cohort_avg_state", {})
    if avg_state:
        lines.append("\n**Cohort Average State (Proxies):**")
        lines.append("| Variable | Value |")
        lines.append("|----------|-------|")
        for key, value in sorted(avg_state.items()):
            lines.append(f"| {key} | {value:.3f} |")

    return "\n".join(lines)


def generate_hypothesis_sequences_section(qratum_results: dict[str, Any]) -> str:
    """Generate hypothesis sequences section."""
    if qratum_results.get("status") != "complete":
        return "*QRATUM analysis not performed*"

    sequences = qratum_results.get("sequences", [])
    if not sequences:
        return "*No sequences generated*"

    lines = []
    lines.append("> **⚠️ RESEARCH HYPOTHESES ONLY**")
    lines.append("> These sequences require experimental validation and clinical trials.")
    lines.append("> NOT for clinical treatment decisions.\n")

    for i, seq in enumerate(sequences[:10], 1):
        lines.append(f"### Sequence {i}: `{seq.get('sequence_id', 'N/A')[:8]}`\n")

        # Scores
        lines.append("**Scores:**")
        lines.append(f"- Efficacy: {seq.get('total_efficacy', 0):.3f}")
        lines.append(f"- Toxicity: {seq.get('total_toxicity', 0):.3f}")
        lines.append(f"- Resistance Suppression: {seq.get('resistance_suppression_score', 0):.3f}")
        lines.append(f"- Immune Engagement: {seq.get('immune_engagement_score', 0):.3f}")

        # Interventions
        interventions = seq.get("interventions", [])
        if interventions:
            lines.append("\n**Intervention Schedule:**")
            lines.append("| Week | Drug | Dosage |")
            lines.append("|------|------|--------|")
            for intv in interventions:
                lines.append(
                    f"| {intv.get('timing_week', 'N/A')} | "
                    f"{intv.get('drug_name', 'N/A')} | "
                    f"{intv.get('dosage', 0)*100:.0f}% |"
                )

        # Risk flags
        risks = seq.get("risk_flags", [])
        if risks:
            lines.append("\n**Risk Flags:**")
            for risk in risks:
                lines.append(f"- ⚠️ {risk}")

        lines.append("")

    return "\n".join(lines)


def generate_sensitivity_section() -> str:
    """Generate sensitivity analysis section."""
    return """
> **Note:** Sensitivity analyses should be performed by varying key parameters:
> - Gap days for line-of-therapy definition (28, 45, 60 days)
> - Follow-up window duration
> - Minimum cell size threshold
>
> Re-run the pipeline with different parameters to assess stability of findings.
"""


def generate_limitations_section() -> str:
    """Generate limitations section."""
    return """
### Medicare Population Bias
- Cohort limited to Medicare beneficiaries (primarily age 65+)
- Results may not generalize to younger populations
- Medicare Advantage enrollment may affect claims completeness

### Claims-Based Limitations
- Treatment timing reflects billing, not administration
- Diagnosis codes may not capture full clinical picture
- Drug identification relies on J-code mappings (not all drugs captured)
- Line-of-therapy is approximated from gaps in treatment

### Proxy Variables
- **Tumor burden proxy:** Based on healthcare utilization, NOT tumor measurements
- **Immune engagement proxy:** Based on treatment codes, NOT immune function
- **Toxicity proxy:** Based on acute care use, NOT direct toxicity assessment
- All proxies require clinical validation before interpretation

### Selection and Survivor Bias
- Analysis conditional on linkage and enrollment
- Patients must survive to receive treatments
- Immortal time bias possible in time-to-treatment analyses

### Retrospective Design
- Cannot establish causation from observational data
- Unmeasured confounding likely
- Results are hypothesis-generating only
"""


def generate_manifest_section(manifest: dict[str, Any]) -> str:
    """Generate manifest section for reproducibility appendix."""
    if not manifest:
        return "*No manifest available*"

    lines = []
    lines.append(f"- **Created:** {manifest.get('created_at', 'N/A')}")
    lines.append(f"- **File Count:** {manifest.get('file_count', 'N/A')}")
    lines.append(f"- **Total Size:** {manifest.get('total_size_bytes', 0):,} bytes")

    return "\n".join(lines)


def build_report(run_dir: Path) -> str:
    """Build the complete report from artifacts.

    Args:
        run_dir: Path to pipeline run directory

    Returns:
        Complete Markdown report
    """
    # Load all artifact files
    run_config = load_json_file(run_dir / "run_config.json")
    manifest = load_json_file(run_dir / "dataset_manifest.json")
    cohort_counts = load_json_file(run_dir / "cohort_counts.json")
    timeline_summary = load_json_file(run_dir / "timeline_summary.json")
    qratum_results = load_json_file(run_dir / "qratum_sequences.json")
    dua_checklist = load_json_file(run_dir / "dua_checklist.json")
    environment_info = load_text_file(run_dir / "environment.txt")
    git_commit = load_text_file(run_dir / "git_commit.txt")

    # Generate report sections
    report = REPORT_TEMPLATE.format(
        timestamp=datetime.now(timezone.utc).isoformat(),
        run_dir=str(run_dir),
        executive_summary=generate_executive_summary(
            cohort_counts, timeline_summary, qratum_results
        ),
        data_sources_section=generate_data_sources_section(manifest),
        dua_checklist_section=generate_dua_checklist_section(dua_checklist),
        cohort_criteria_section=generate_cohort_criteria_section(run_config),
        cohort_flow_section=generate_cohort_flow_section(cohort_counts),
        cohort_characteristics_section=generate_cohort_characteristics_section(cohort_counts),
        time_to_treatment_section=generate_time_to_treatment_section(timeline_summary),
        treatment_sequences_section=generate_treatment_sequences_section(timeline_summary),
        lines_of_therapy_section=generate_lines_of_therapy_section(timeline_summary),
        causal_graph_section=generate_causal_graph_section(qratum_results),
        hypothesis_sequences_section=generate_hypothesis_sequences_section(qratum_results),
        sensitivity_section=generate_sensitivity_section(),
        limitations_section=generate_limitations_section(),
        run_config_json=json.dumps(run_config, indent=2, default=str),
        environment_info=environment_info,
        git_commit=git_commit,
        manifest_section=generate_manifest_section(manifest),
    )

    return report


def try_generate_pdf(markdown_content: str, output_path: Path) -> bool:
    """Try to generate PDF from Markdown.

    Args:
        markdown_content: Markdown content
        output_path: Output PDF path

    Returns:
        True if successful, False otherwise
    """
    # Try markdown2pdf or similar
    try:
        import markdown
        from reportlab.lib.pagesizes import letter
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
        from reportlab.lib.styles import getSampleStyleSheet

        # This is a simplified PDF generation
        # For production, consider using weasyprint or pandoc

        logger.info("PDF generation with reportlab not fully implemented")
        logger.info("Please use pandoc or similar tool to convert REPORT.md to PDF")
        return False

    except ImportError:
        logger.info("PDF generation requires additional dependencies")
        logger.info("Install reportlab or use pandoc: pandoc REPORT.md -o REPORT.pdf")
        return False


def main() -> None:
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Generate SEER-Medicare analysis report from pipeline artifacts"
    )
    parser.add_argument(
        "--run_dir",
        type=str,
        required=True,
        help="Path to pipeline run directory containing artifacts",
    )
    parser.add_argument(
        "--output_name",
        type=str,
        default="REPORT",
        help="Base name for output files (default: REPORT)",
    )
    parser.add_argument(
        "--generate_pdf",
        action="store_true",
        help="Attempt to generate PDF (requires additional dependencies)",
    )

    args = parser.parse_args()
    run_dir = Path(args.run_dir)

    if not run_dir.exists():
        logger.error(f"Run directory not found: {run_dir}")
        sys.exit(1)

    logger.info(f"Generating report from: {run_dir}")

    # Build report
    report_content = build_report(run_dir)

    # Save Markdown
    md_path = run_dir / f"{args.output_name}.md"
    with open(md_path, "w") as f:
        f.write(report_content)
    logger.info(f"Markdown report saved: {md_path}")

    # Optionally generate PDF
    if args.generate_pdf:
        pdf_path = run_dir / f"{args.output_name}.pdf"
        if try_generate_pdf(report_content, pdf_path):
            logger.info(f"PDF report saved: {pdf_path}")
        else:
            logger.info(f"To generate PDF, run: pandoc {md_path} -o {pdf_path}")

    print(f"\nReport generated: {md_path}")
    print("To convert to PDF: pandoc REPORT.md -o REPORT.pdf")


if __name__ == "__main__":
    main()
